{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fatal Accidents Analysis\n",
    "\n",
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Gather data sources\n",
    "\n",
    "2. Load and clean up\n",
    "\n",
    "3. Confirm data quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required modules \n",
    "import os\n",
    "import arcgis\n",
    "from arcgis.features import GeoAccessor, GeoSeriesAccessor\n",
    "import arcpy\n",
    "import pandas as pd\n",
    "import glob\n",
    "import zipfile\n",
    "from simpledbf import Dbf5\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set and Change directory to workspace\n",
    "root_dir = os.path.join(os.getcwd(), r\"../..\")\n",
    "workspace_dir = os.path.join(root_dir, \"workspace\")\n",
    "data_dir = os.path.join(root_dir, \"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Gather data sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need two types of data: \n",
    "\n",
    "- A. Fatal accident location data \n",
    "- B. US Interstate with traffic volumes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Fatal accident location data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zipped FARS datasets for 2008-2017 have already been downloaded from ftp://ftp.nhtsa.dot.gov/fars/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FARS2008.zip',\n",
       " 'FARS2009.zip',\n",
       " 'FARS2010.zip',\n",
       " 'FARS2011.zip',\n",
       " 'FARS2012.zip',\n",
       " 'FARS2013NationalDBF.zip',\n",
       " 'FARS2014NationalDBF.zip',\n",
       " 'FARS2015NationalCSV.zip',\n",
       " 'FARS2016NationalCSV.zip',\n",
       " 'FARS2017NationalCSV.zip']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's unzip each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipping file FARS2008.zip...\n",
      "Unzipping file FARS2009.zip...\n",
      "Unzipping file FARS2010.zip...\n",
      "Unzipping file FARS2011.zip...\n",
      "Unzipping file FARS2012.zip...\n",
      "Unzipping file FARS2013NationalDBF.zip...\n",
      "Unzipping file FARS2014NationalDBF.zip...\n",
      "Unzipping file FARS2015NationalCSV.zip...\n",
      "Unzipping file FARS2016NationalCSV.zip...\n",
      "Unzipping file FARS2017NationalCSV.zip...\n",
      "Final list of unzipped files:\n",
      "['C:\\\\Users\\\\albe9057\\\\Documents\\\\GitHub\\\\fatal_accidents_spatial_analysis\\\\src\\\\NHTSA_Analysis_2018\\\\../..\\\\data\\\\FARS2008', 'C:\\\\Users\\\\albe9057\\\\Documents\\\\GitHub\\\\fatal_accidents_spatial_analysis\\\\src\\\\NHTSA_Analysis_2018\\\\../..\\\\data\\\\FARS2009', 'C:\\\\Users\\\\albe9057\\\\Documents\\\\GitHub\\\\fatal_accidents_spatial_analysis\\\\src\\\\NHTSA_Analysis_2018\\\\../..\\\\data\\\\FARS2010', 'C:\\\\Users\\\\albe9057\\\\Documents\\\\GitHub\\\\fatal_accidents_spatial_analysis\\\\src\\\\NHTSA_Analysis_2018\\\\../..\\\\data\\\\FARS2011', 'C:\\\\Users\\\\albe9057\\\\Documents\\\\GitHub\\\\fatal_accidents_spatial_analysis\\\\src\\\\NHTSA_Analysis_2018\\\\../..\\\\data\\\\FARS2012', 'C:\\\\Users\\\\albe9057\\\\Documents\\\\GitHub\\\\fatal_accidents_spatial_analysis\\\\src\\\\NHTSA_Analysis_2018\\\\../..\\\\data\\\\FARS2013NationalDBF', 'C:\\\\Users\\\\albe9057\\\\Documents\\\\GitHub\\\\fatal_accidents_spatial_analysis\\\\src\\\\NHTSA_Analysis_2018\\\\../..\\\\data\\\\FARS2014NationalDBF', 'C:\\\\Users\\\\albe9057\\\\Documents\\\\GitHub\\\\fatal_accidents_spatial_analysis\\\\src\\\\NHTSA_Analysis_2018\\\\../..\\\\data\\\\FARS2015NationalCSV', 'C:\\\\Users\\\\albe9057\\\\Documents\\\\GitHub\\\\fatal_accidents_spatial_analysis\\\\src\\\\NHTSA_Analysis_2018\\\\../..\\\\data\\\\FARS2016NationalCSV', 'C:\\\\Users\\\\albe9057\\\\Documents\\\\GitHub\\\\fatal_accidents_spatial_analysis\\\\src\\\\NHTSA_Analysis_2018\\\\../..\\\\data\\\\FARS2017NationalCSV']\n"
     ]
    }
   ],
   "source": [
    "unzipped_files_list = []\n",
    "for file in os.listdir(data_dir):\n",
    "    print(\"Unzipping file {0}...\".format(file))\n",
    "    target_name = os.path.join(data_dir, file.split('.')[0])\n",
    "    zip_ref = zipfile.ZipFile(os.path.join(data_dir, file), 'r')\n",
    "    zip_ref.extractall(target_name)\n",
    "    zip_ref.close()\n",
    "    unzipped_files_list.append(target_name)\n",
    "print(\"Final list of unzipped files:\")    \n",
    "print(unzipped_files_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each year (in our unzipped_files_list), we need to create a feature class of accidents. Let's start by creating a file geodatabase where our yearly files will reside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\albe9057\\\\Documents\\\\GitHub\\\\fatal_accidents_spatial_analysis\\\\src\\\\NHTSA_Analysis_2018\\\\../..\\\\data\\\\FARSData.gdb'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fars_fgdb = arcpy.CreateFileGDB_management(data_dir, \"FARSData.gdb\").getOutput(0)\n",
    "fars_fgdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know each year has an accidents table, but some are in CSV format and others are in DBF format. Let's iterate and try to handle that logic for both cases. We also need to use logic to find the right Latitude and Longitude fields when spatially enabling each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing C:\\Users\\albe9057\\Documents\\GitHub\\fatal_accidents_spatial_analysis\\src\\NHTSA_Analysis_2018\\../..\\data\\FARS2008...\n",
      "Retrieving accidents table...\n",
      "C:\\Users\\albe9057\\Documents\\GitHub\\fatal_accidents_spatial_analysis\\data\\FARS2008\\ACCIDENT.DBF\n",
      "DBF\n",
      "34172\n",
      "33691\n",
      "\n",
      "Processing C:\\Users\\albe9057\\Documents\\GitHub\\fatal_accidents_spatial_analysis\\src\\NHTSA_Analysis_2018\\../..\\data\\FARS2009...\n",
      "Retrieving accidents table...\n",
      "C:\\Users\\albe9057\\Documents\\GitHub\\fatal_accidents_spatial_analysis\\data\\FARS2009\\accident.DBF\n",
      "DBF\n",
      "30862\n",
      "30499\n",
      "\n",
      "Processing C:\\Users\\albe9057\\Documents\\GitHub\\fatal_accidents_spatial_analysis\\src\\NHTSA_Analysis_2018\\../..\\data\\FARS2010...\n",
      "Retrieving accidents table...\n",
      "C:\\Users\\albe9057\\Documents\\GitHub\\fatal_accidents_spatial_analysis\\data\\FARS2010\\accident.dbf\n",
      "dbf\n",
      "0\n",
      "0\n",
      "Unexpected error:\n",
      "(<class 'TypeError'>, TypeError('Cannot index by location index with a non-integer key',), <traceback object at 0x000001F8D4D33648>)\n",
      "\n",
      "Processing C:\\Users\\albe9057\\Documents\\GitHub\\fatal_accidents_spatial_analysis\\src\\NHTSA_Analysis_2018\\../..\\data\\FARS2011...\n",
      "Retrieving accidents table...\n",
      "C:\\Users\\albe9057\\Documents\\GitHub\\fatal_accidents_spatial_analysis\\data\\FARS2011\\accident.dbf\n",
      "dbf\n",
      "0\n",
      "0\n",
      "Unexpected error:\n",
      "(<class 'TypeError'>, TypeError('Cannot index by location index with a non-integer key',), <traceback object at 0x000001F8D49747C8>)\n",
      "\n",
      "Processing C:\\Users\\albe9057\\Documents\\GitHub\\fatal_accidents_spatial_analysis\\src\\NHTSA_Analysis_2018\\../..\\data\\FARS2012...\n",
      "Retrieving accidents table...\n",
      "C:\\Users\\albe9057\\Documents\\GitHub\\fatal_accidents_spatial_analysis\\data\\FARS2012\\accident.dbf\n",
      "dbf\n",
      "0\n",
      "0\n",
      "Unexpected error:\n",
      "(<class 'TypeError'>, TypeError('Cannot index by location index with a non-integer key',), <traceback object at 0x000001F8D4990908>)\n",
      "\n",
      "Processing C:\\Users\\albe9057\\Documents\\GitHub\\fatal_accidents_spatial_analysis\\src\\NHTSA_Analysis_2018\\../..\\data\\FARS2013NationalDBF...\n",
      "Retrieving accidents table...\n",
      "C:\\Users\\albe9057\\Documents\\GitHub\\fatal_accidents_spatial_analysis\\data\\FARS2013NationalDBF\\accident.dbf\n",
      "dbf\n",
      "0\n",
      "0\n",
      "Unexpected error:\n",
      "(<class 'TypeError'>, TypeError('Cannot index by location index with a non-integer key',), <traceback object at 0x000001F8D3F60988>)\n",
      "\n",
      "Processing C:\\Users\\albe9057\\Documents\\GitHub\\fatal_accidents_spatial_analysis\\src\\NHTSA_Analysis_2018\\../..\\data\\FARS2014NationalDBF...\n",
      "Retrieving accidents table...\n",
      "C:\\Users\\albe9057\\Documents\\GitHub\\fatal_accidents_spatial_analysis\\data\\FARS2014NationalDBF\\accident.dbf\n",
      "dbf\n",
      "0\n",
      "0\n",
      "Unexpected error:\n",
      "(<class 'TypeError'>, TypeError('Cannot index by location index with a non-integer key',), <traceback object at 0x000001F8D3F4E148>)\n",
      "\n",
      "Processing C:\\Users\\albe9057\\Documents\\GitHub\\fatal_accidents_spatial_analysis\\src\\NHTSA_Analysis_2018\\../..\\data\\FARS2015NationalCSV...\n",
      "Retrieving accidents table...\n",
      "C:\\Users\\albe9057\\Documents\\GitHub\\fatal_accidents_spatial_analysis\\data\\FARS2015NationalCSV\\accident.csv\n",
      "csv\n",
      "32538\n",
      "32396\n",
      "\n",
      "Processing C:\\Users\\albe9057\\Documents\\GitHub\\fatal_accidents_spatial_analysis\\src\\NHTSA_Analysis_2018\\../..\\data\\FARS2016NationalCSV...\n",
      "Retrieving accidents table...\n",
      "C:\\Users\\albe9057\\Documents\\GitHub\\fatal_accidents_spatial_analysis\\data\\FARS2016NationalCSV\\accident.csv\n",
      "csv\n",
      "34748\n",
      "34619\n",
      "\n",
      "Processing C:\\Users\\albe9057\\Documents\\GitHub\\fatal_accidents_spatial_analysis\\src\\NHTSA_Analysis_2018\\../..\\data\\FARS2017NationalCSV...\n",
      "Retrieving accidents table...\n",
      "C:\\Users\\albe9057\\Documents\\GitHub\\fatal_accidents_spatial_analysis\\data\\FARS2017NationalCSV\\accident.csv\n",
      "csv\n",
      "34247\n",
      "34011\n"
     ]
    }
   ],
   "source": [
    "for unzipped_file in unzipped_files_list:\n",
    "    try:\n",
    "        print(\"\\nProcessing {0}...\".format(unzipped_file))\n",
    "        print(\"Retrieving accidents table...\")\n",
    "        os.chdir(unzipped_file)\n",
    "\n",
    "        accident_table = os.path.join(os.getcwd(), glob.glob(\"accident*\")[0])\n",
    "        print(accident_table)\n",
    "\n",
    "        file_extension = accident_table.split(\".\")[-1]\n",
    "        print(file_extension)\n",
    "\n",
    "        if file_extension.lower() == \"csv\":\n",
    "            accident_df = pd.read_csv(accident_table)\n",
    "\n",
    "        elif file_extension.lower() == \"dbf\":\n",
    "            accident_df = Dbf5(accident_table).to_dataframe()\n",
    "\n",
    "        else:\n",
    "            print(\"WARNING: the unzipped file '{0}' did not contain an accident table with a recognizable file format!\")\n",
    "\n",
    "        # Find the appropriate latitude and longitude columns\n",
    "        columns = accident_df.columns.tolist()\n",
    "        latitude = process.extractOne('LATITUDE', columns)[0]\n",
    "        longitude = process.extractOne('LONGITUDE', columns)[0]\n",
    "        \n",
    "        # Filter for dummy lat/lon values\n",
    "        print(accident_df.shape[0])\n",
    "        accident_df = accident_df.loc[accident_df[longitude] < 360]\n",
    "        print(accident_df.shape[0])\n",
    "\n",
    "        # Convert the accident DF to a spatially-enabled dataframe using the lat/lon columns\n",
    "        accident_sedf = accident_df.spatial.from_xy(accident_df, x_column=longitude, y_column=latitude)\n",
    "        year = accident_sedf.iloc[0]['YEAR'].astype('str').split(\".\")[0]\n",
    "\n",
    "        # Convert the SEDF to a feature class\n",
    "        accident_fc = accident_sedf.spatial.to_featureclass(os.path.join(fars_fgdb, \"accident_{0}\".format(year)))\n",
    "    except:\n",
    "        print(\"Unexpected error:\")\n",
    "        print(sys.exc_info())\n",
    "#         raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## >>>>> Construction Zone <<<<<"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "folder = os.listdir(data_dir)[1]\n",
    "folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "os.chdir(unzipped_files_list[1])\n",
    "glob.glob(\"accident*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "os.path.join(os.getcwd(), glob.glob(\"accident*\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "accident_table = os.path.join(os.getcwd(), glob.glob(\"accident*\")[0])\n",
    "\n",
    "file_extension = accident_table.split(\".\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "file_extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accident_df = pd.DataFrame.from_csv(accident_table)\n",
    "accident_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accident_df = Dbf5(accident_table).to_dataframe()\n",
    "accident_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns = accident_df.columns.tolist()\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "latitude = fuzzywuzzy.process.extractOne('LATITUDE', columns)[0]\n",
    "longitude = fuzzywuzzy.process.extractOne('LONGITUDE', columns)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "accident_sedf = accident_df.spatial.from_xy(accident_df, x_column=longitude, y_column=latitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "year = accident_sedf.iloc[0]['YEAR'].astype('str').split(\".\")[0]\n",
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fc = accident_sedf.spatial.to_featureclass(os.path.join(fars_fgdb, \"accident_{0}\".format(year)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fars_fgdb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
