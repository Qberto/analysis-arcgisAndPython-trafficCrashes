{"nbformat_minor":2,"metadata":{"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","file_extension":".py","version":"3.6.7"},"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"}},"cells":[{"metadata":{},"source":"# <span style=\"color:purple\">Example: <\/span><span>Automated Road Condition Assessment<\/span>","cell_type":"markdown"},{"metadata":{},"source":"![Road Damage Detection](https://github.com/Qberto/FedGIS_2019/blob/master/Plenary_ArcGISNotebooks/notebooks/images/ChesapeakeBayBridgeTunnel_Driving_GIF.gif?raw=true \"Road Damage Detection\")","cell_type":"markdown"},{"metadata":{"heading_collapsed":true},"source":"# <span style=\"color:purple\">TensorFlow: <\/span><span>Object Detection of Road Damage features<\/span>","cell_type":"markdown"},{"metadata":{"hidden":true},"source":"### The training and test data consists of 9,053 photographs, collected from smartphone cameras, hand labeled with the presence or absence of 8 road damage categories.","cell_type":"markdown"},{"metadata":{"hidden":true},"source":"![GIF](https://github.com/Qberto/FedGIS_2019/blob/master/Plenary_ArcGISNotebooks/notebooks/images/trainingdata01.PNG?raw=true \"training data\")","cell_type":"markdown"},{"outputs":[{"output_type":"stream","name":"stdout","text":"Enter password: ········\n"},{"metadata":{},"output_type":"execute_result","data":{"text/html":"GIS @ <a href=\"https://esrifederal.maps.arcgis.com\">https://esrifederal.maps.arcgis.com<\/a>","text/plain":"GIS @ https://esrifederal.maps.arcgis.com version:6.4"},"execution_count":2}],"metadata":{"trusted":true,"scrolled":true},"execution_count":2,"source":"from arcgis.gis import GIS\ngis = GIS(\"https://esrifederal.maps.arcgis.com\", username=\"Anieto_esrifederal\")\ngis","cell_type":"code"},{"outputs":[],"metadata":{"trusted":true},"execution_count":4,"source":"def fault_counter(classes_arr, scores_arr, score_thresh=0.3):\n    # Process the numpy array of classes from the model\n    stacked_arr = np.stack((classes_arr, scores_arr), axis=-1)\n    # Convert to pandas dataframe for easier querying\n    detection_df = pd.DataFrame(stacked_arr)\n    \n    # Retrieve total count of each fault\n    detected_D00 = detection_df[(detection_df[0] == 1.0) & (detection_df[1] > score_thresh)]\n    detected_D01 = detection_df[(detection_df[0] == 2.0) & (detection_df[1] > score_thresh)]\n    detected_D10 = detection_df[(detection_df[0] == 3.0) & (detection_df[1] > score_thresh)]\n    detected_D11 = detection_df[(detection_df[0] == 4.0) & (detection_df[1] > score_thresh)]\n    detected_D20 = detection_df[(detection_df[0] == 5.0) & (detection_df[1] > score_thresh)]\n    detected_D40 = detection_df[(detection_df[0] == 6.0) & (detection_df[1] > score_thresh)]\n    detected_D43 = detection_df[(detection_df[0] == 7.0) & (detection_df[1] > score_thresh)]\n    detected_D44 = detection_df[(detection_df[0] == 8.0) & (detection_df[1] > score_thresh)]\n    \n    lon_cracks_count = len(detected_D00) + len(detected_D01)\n    lat_cracks_count = len(detected_D10) + len(detected_D11)\n    allig_cracks_count = len(detected_D20)\n    othcorr_count = len(detected_D40) + len(detected_D43) + len(detected_D44)\n    \n    return lon_cracks_count, lat_cracks_count, allig_cracks_count, othcorr_count","cell_type":"code"},{"metadata":{"heading_collapsed":true},"source":"# <span style=\"color:purple\">ArcPy: <\/span><span>Density-based Clustering and Directional Distribution to Find Important Zones<\/span>","cell_type":"markdown"},{"metadata":{},"source":"![GIF](https://github.com/Qberto/FedGIS_2019/blob/master/Plenary_ArcGISNotebooks/notebooks/images/bridge_both.JPG?raw=true \"training data\")","cell_type":"markdown"},{"outputs":[],"metadata":{"trusted":true},"execution_count":null,"source":"overwrite_attachment = True\n\nupload_source = False\n\ninput_images = glob.glob('{0}\\\\*.png'.format(input_images_dir))\n\nwith detection_graph.as_default():\n    \n    with tf.Session(graph=detection_graph) as sess:\n        \n        image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n        detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n        detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n        detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n        num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n        \n        for image in input_images:\n            image_id = image.split(\"\\\\\")[-1].split(\".png\")[0].split('_')[1]\n            object_id = str(int(float(image_id) * 2))\n            print(\"Processing image {0}...\".format(image))\n            print(\"\\tSecond stamp: {0}\".format(image_id))\n            print(\"\\tObject ID: {0}\".format(object_id))\n            image = Image.open(image)\n            area = (650, 720, 1270, 950)\n            image = image.crop(area)\n            # the array based representation of the image will be used later in order to prepare the\n            # result image with boxes and labels on it.\n            image_np = load_image_into_numpy_array(image)\n            # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n            image_np_expanded = np.expand_dims(image_np, axis=0)\n            # Actual detection.\n            (boxes, scores, classes, num) = sess.run(\n              [detection_boxes, detection_scores, detection_classes, num_detections],\n              feed_dict={image_tensor: image_np_expanded})\n            # Visualization of the results of a detection.\n            vis_util.visualize_boxes_and_labels_on_image_array(\n                                                              image_np,\n                                                              np.squeeze(boxes),\n                                                              np.squeeze(classes).astype(np.int32),\n                                                              np.squeeze(scores),\n                                                              category_index,\n                                                              min_score_thresh=0.3,\n                                                              use_normalized_coordinates=True,\n                                                              line_thickness=8)\n            \n            lon_cracks_count, lat_cracks_count, allig_cracks_count, othcorr_count = fault_counter(np.squeeze(classes).astype(np.int32), np.squeeze(scores))\n                \n            # Retrieve the feature from the feature layer to update\n            obj_fset = object_point_lyr.query(where=\"\"\"OBJECTID = '\"\"\"+str(object_id)+\"\"\"'\"\"\", return_geometry=False)  \n            all_features = obj_fset.features\n            original_feature = all_features[0]\n            feature_to_be_updated = deepcopy(original_feature)\n                \n            features_for_update = []\n\n            feature_to_be_updated.attributes['LongitudinalCrackCount'] = lon_cracks_count\n            feature_to_be_updated.attributes['LateralCrackCount'] = lat_cracks_count\n            feature_to_be_updated.attributes['AlligatorCrackCount'] = allig_cracks_count\n            feature_to_be_updated.attributes['OtherCorruptionCount'] = othcorr_count\n                                                            \n            # Store attribute updates and send edit request\n            features_for_update.append(feature_to_be_updated)\n            object_point_lyr.edit_features(updates=features_for_update)    \n        \n            # Perform attachment of detected image\n            scipy.misc.imsave('detected_faults.jpg', image_np)\n            obj_id = feature_to_be_updated.attributes['OBJECTID']\n\n            if overwrite_attachment:\n                for attachment in object_point_lyr.attachments.get_list(obj_id):\n                    object_point_lyr.attachments.delete(obj_id, attachment['id'])\n\n            object_point_lyr.attachments.add(obj_id, 'detected_faults.jpg')\n\n            if upload_source:\n                object_point_lyr.attachments.add(obj_id, 'source.jpg')","cell_type":"code"},{"metadata":{"heading_collapsed":true},"source":"# <span style=\"color:purple\">ArcGIS API for Python: <\/span><span>Publish Analysis, Configure Group, and Share With Field Crew<\/span>","cell_type":"markdown"},{"outputs":[],"metadata":{"trusted":true},"execution_count":5,"source":"def update_hosted_service_feature(source_label, \n                                  observation_id, \n                                  source_image_localpath, \n                                  source_datetime,\n                                  target_service, \n                                  target_label_field, \n                                  target_camera_id_field, \n                                  overwrite_attachment=True, layer_index=0):\n    \n    # Convert our existing service into a pandas dataframe\n    target_lyr = target_service.layers[layer_index]   \n    target_fset = target_lyr.query(where=\"\"\"OBJECTID = '\"\"\"+str(observation_id)+\"\"\"'\"\"\", return_geometry=False)  \n    all_features = target_fset.features\n    original_feature = all_features[0]\n    feature_to_be_updated = deepcopy(original_feature)\n    \n    features_for_update = []\n\n    feature_to_be_updated.attributes['LinearCrack'] = car_count\n    feature_to_be_updated.attributes['LinearCrackCount'] = truck_count\n    \n    feature_to_be_updated.attributes['LongitudinalCrack'] = people_count\n    feature_to_be_updated.attributes['LongitudinalCrackCount'] = people_count\n    \n    feature_to_be_updated.attributes['LateralCrack'] = bus_count\n    feature_to_be_updated.attributes['LateralCrackCount'] = bus_count\n    \n    feature_to_be_updated.attributes['AlligatorCrack'] = truck_count\n    feature_to_be_updated.attributes['AlligatorCrackCount'] = truck_count\n    \n    feature_to_be_updated.attributes['OtherCorruption'] = truck_count\n    feature_to_be_updated.attributes['OtherCorruptionCount'] = truck_count\n    \n    # Store attribute updates and send edit request\n    features_for_update.append(feature_to_be_updated)\n    target_lyr.edit_features(updates=features_for_update) \n    \n    # Perform attachment of detected image\n    obj_id = feature_to_be_updated.attributes['OBJECTID']\n    \n    if overwrite_attachment:\n        for attachment in target_lyr.attachments.get_list(obj_id):\n            target_lyr.attachments.delete(obj_id, attachment['id'])\n\n    target_lyr.attachments.add(obj_id, source_image_localpath)","cell_type":"code"},{"outputs":[{"metadata":{},"output_type":"execute_result","data":{"text/html":"\n        <iframe\n            width=\"1366\"\n            height=\"600\"\n            src=\"https://esrifederal.maps.arcgis.com/apps/opsdashboard/index.html#/889e9521ef3241b68d145fc0367d20fa\"\n            frameborder=\"0\"\n            allowfullscreen\n        ><\/iframe>\n        ","text/plain":"<IPython.lib.display.IFrame at 0x7fecf21155c0>"},"execution_count":3}],"metadata":{"trusted":true},"execution_count":3,"source":"from IPython.display import IFrame\nIFrame('https://esrifederal.maps.arcgis.com/apps/opsdashboard/index.html#/889e9521ef3241b68d145fc0367d20fa', width=1366, height=600)","cell_type":"code"}],"nbformat":4}